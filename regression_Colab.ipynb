{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ApplesDaddy/CMPT353Project/blob/main/regression_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bzcUpUE0AXlq",
    "outputId": "92983304-ed35-40e9-9d3d-e4feaeabaeb2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'conda' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'which' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.11.4\n",
      "$PYTHONPATH\n"
     ]
    }
   ],
   "source": [
    "!conda --version\n",
    "!which python\n",
    "!python --version\n",
    "!echo $PYTHONPATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QIv0kXQnAezZ",
    "outputId": "e877fbbe-4fa9-4fd2-9af9-3249ff0cfbe6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PYTHONPATH=\n",
      "$PYTHONPATH\n"
     ]
    }
   ],
   "source": [
    "%env PYTHONPATH=\n",
    "!echo $PYTHONPATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TTsbGKwlAhxg",
    "outputId": "4d50856f-5dc9-4aba-d13f-3de00f2e1552"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'chmod' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "/bin/bash: ./Miniconda3-py310_24.1.2-0-Linux-x86_64.sh: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "# most recent install link from https://docs.anaconda.com/free/miniconda/miniconda-other-installer-links/\n",
    "!wget https://repo.anaconda.com/miniconda/Miniconda3-py310_24.1.2-0-Linux-x86_64.sh\n",
    "!chmod +x Miniconda3-py310_24.1.2-0-Linux-x86_64.sh\n",
    "!bash ./Miniconda3-py310_24.1.2-0-Linux-x86_64.sh -b -f -p /usr/local/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "40iV0gF0Al-o",
    "outputId": "e3695b07-02f2-4045-8969-c1a9e296a1d7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'which' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'conda' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'conda' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'conda' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!which conda\n",
    "!conda --version\n",
    "!conda install --channel defaults conda python=3.10 --yes\n",
    "!conda update --channel defaults --all --yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ne1dBaTMAqsW",
    "outputId": "441103b8-f2d4-4b9c-c3eb-b58351ffefd4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\17788\\\\OneDrive - Simon Fraser University (1sfu)\\\\Desktop\\\\School\\\\CMPT353\\\\Project\\\\CMPT353Project',\n",
       " 'C:\\\\Users\\\\17788\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311',\n",
       " 'C:\\\\Users\\\\17788\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\python311.zip',\n",
       " 'C:\\\\Users\\\\17788\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\DLLs',\n",
       " 'C:\\\\Users\\\\17788\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib',\n",
       " '',\n",
       " 'C:\\\\Users\\\\17788\\\\AppData\\\\Roaming\\\\Python\\\\Python311\\\\site-packages',\n",
       " 'C:\\\\Users\\\\17788\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages',\n",
       " 'C:\\\\Users\\\\17788\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\win32',\n",
       " 'C:\\\\Users\\\\17788\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\win32\\\\lib',\n",
       " 'C:\\\\Users\\\\17788\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\Pythonwin']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zaZIJrlwAy7i",
    "outputId": "c619502c-be06-418d-cd47-87ab31744938"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'ls' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!ls /usr/local/lib/python3.10/dist-packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "jyuXRyuBA2UT"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'conda' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "sys.path.append(\"/usr/local/lib/python3.10/site-packages\")\n",
    "!conda config --add channels conda-forge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pOjhPejhA8iJ",
    "outputId": "42e08a79-d717-4232-f4cf-6f3e2c8dc38b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'conda' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!conda create --name musemotion_meta -c conda-forge numpy pandas matplotlib scikit-learn wandb pytorch torchvision torchaudio pytorch-cuda=12.1 -c pytorch -c nvidia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YM_HmfVOB722",
    "outputId": "5af753e7-2f17-44d6-f2bd-0452d67ffa8c"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1993114121.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[9], line 5\u001b[1;36m\u001b[0m\n\u001b[1;33m    eval \"$(conda shell.bash hook)\"\u001b[0m\n\u001b[1;37m         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# !conda init\n",
    "# !conda activate musemotion_meta\n",
    "# credit https://stackoverflow.com/a/62668276\n",
    "%%shell\n",
    "eval \"$(conda shell.bash hook)\"\n",
    "conda activate musemotion_meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FvutftOdALuH"
   },
   "source": [
    "# Load data\n",
    "_Note_: tempo = bpm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8aCwHWW6DruL",
    "outputId": "ee617066-4780-4166-d1b7-17c89923760f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('datasets/full_data.csv', <http.client.HTTPMessage at 0x29d7aaf1b10>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "urllib.request.urlretrieve(\"https://github.com/zhandrew4/music-mood-classification/raw/main/muse_v3.csv\", \"datasets/muse_v3.csv\")\n",
    "urllib.request.urlretrieve(\"https://github.com/zhandrew4/music-mood-classification/raw/main/full_data.csv\", \"datasets/full_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iqZpfbtQHYL1",
    "outputId": "980796d6-323b-424a-ac95-70918518a940"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'track', 'artist', 'seeds', 'spotify_id', 'danceability',\n",
       "       'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness',\n",
       "       'instrumentalness', 'liveness', 'valence', 'tempo', 'type', 'id', 'uri',\n",
       "       'track_href', 'analysis_url', 'duration_ms', 'time_signature'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "sample = pd.read_csv(\"datasets/full_data.csv\", nrows=3)\n",
    "sample.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 455
    },
    "id": "4LbDwYR7ALuK",
    "outputId": "5b83fa78-ad82-42e3-fffe-2caf9b651fa9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17788\\AppData\\Local\\Temp\\ipykernel_32244\\842477347.py:9: FutureWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  songs_df = pd.read_csv(\"datasets/full_data.csv\", usecols=KEEP_COLS_MODEL, parse_dates=True, infer_datetime_format=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>time_signature</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>track</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>'Till I Collapse</th>\n",
       "      <td>Eminem</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.237</td>\n",
       "      <td>171.447</td>\n",
       "      <td>297787</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>St. Anger</th>\n",
       "      <td>Metallica</td>\n",
       "      <td>2</td>\n",
       "      <td>-2.642</td>\n",
       "      <td>185.252</td>\n",
       "      <td>441133</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Speedin'</th>\n",
       "      <td>Rick Ross</td>\n",
       "      <td>1</td>\n",
       "      <td>-4.226</td>\n",
       "      <td>100.059</td>\n",
       "      <td>204960</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bamboo Banga</th>\n",
       "      <td>M.I.A.</td>\n",
       "      <td>9</td>\n",
       "      <td>-4.554</td>\n",
       "      <td>125.984</td>\n",
       "      <td>298360</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Die MF Die</th>\n",
       "      <td>Dope</td>\n",
       "      <td>5</td>\n",
       "      <td>-3.524</td>\n",
       "      <td>126.020</td>\n",
       "      <td>186067</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Secret</th>\n",
       "      <td>Quietdrive</td>\n",
       "      <td>0</td>\n",
       "      <td>-5.126</td>\n",
       "      <td>167.996</td>\n",
       "      <td>258373</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Last of the Rest Was the End</th>\n",
       "      <td>Medications</td>\n",
       "      <td>2</td>\n",
       "      <td>-5.774</td>\n",
       "      <td>144.844</td>\n",
       "      <td>324000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lovechild</th>\n",
       "      <td>Daniel Lanois</td>\n",
       "      <td>10</td>\n",
       "      <td>-20.091</td>\n",
       "      <td>79.476</td>\n",
       "      <td>516280</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Last Inhale</th>\n",
       "      <td>Tapage</td>\n",
       "      <td>2</td>\n",
       "      <td>-8.977</td>\n",
       "      <td>160.011</td>\n",
       "      <td>324258</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unfold</th>\n",
       "      <td>Message To Bears</td>\n",
       "      <td>0</td>\n",
       "      <td>-11.355</td>\n",
       "      <td>96.970</td>\n",
       "      <td>268440</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61627 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            artist  key  loudness    tempo  \\\n",
       "track                                                                        \n",
       "'Till I Collapse                            Eminem    1    -3.237  171.447   \n",
       "St. Anger                                Metallica    2    -2.642  185.252   \n",
       "Speedin'                                 Rick Ross    1    -4.226  100.059   \n",
       "Bamboo Banga                                M.I.A.    9    -4.554  125.984   \n",
       "Die MF Die                                    Dope    5    -3.524  126.020   \n",
       "...                                            ...  ...       ...      ...   \n",
       "Secret                                  Quietdrive    0    -5.126  167.996   \n",
       "The Last of the Rest Was the End       Medications    2    -5.774  144.844   \n",
       "Lovechild                            Daniel Lanois   10   -20.091   79.476   \n",
       "Last Inhale                                 Tapage    2    -8.977  160.011   \n",
       "Unfold                            Message To Bears    0   -11.355   96.970   \n",
       "\n",
       "                                  duration_ms  time_signature  \n",
       "track                                                          \n",
       "'Till I Collapse                       297787               4  \n",
       "St. Anger                              441133               4  \n",
       "Speedin'                               204960               4  \n",
       "Bamboo Banga                           298360               4  \n",
       "Die MF Die                             186067               4  \n",
       "...                                       ...             ...  \n",
       "Secret                                 258373               4  \n",
       "The Last of the Rest Was the End       324000               3  \n",
       "Lovechild                              516280               4  \n",
       "Last Inhale                            324258               4  \n",
       "Unfold                                 268440               4  \n",
       "\n",
       "[61627 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KEEP_COLS_MASTER = [\"track\", \"album\", \"artist\", \"release_date\", \"length\",\n",
    "             \"tempo\", \"key\", \"time_signature\",\n",
    "             \"mood\"]\n",
    "\n",
    "KEEP_COLS_MODEL = [\"track\", \"artist\", \"tempo\", \"key\", \"loudness\", \"time_signature\", \"duration_ms\"]\n",
    "\n",
    "# songs_df = pd.read_csv(\"data_moods.csv\", usecols=KEEP_COLS_MASTER)\n",
    "# make names the indices\n",
    "songs_df = pd.read_csv(\"datasets/full_data.csv\", usecols=KEEP_COLS_MODEL, parse_dates=True, infer_datetime_format=True)\n",
    "songs_df.set_index(\"track\", inplace=True)\n",
    "songs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aEDIeUa4ALuL"
   },
   "source": [
    "Convert dates to numbers, specfically seconds.\n",
    "\n",
    "_Note_: This goddamn dataset only gives the year for some songs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ApctZb1QALuL"
   },
   "outputs": [],
   "source": [
    "# print(songs_df[songs_df[\"release_date\"]==\"1993\"])\n",
    "# # credit https://stackoverflow.com/a/54312941\n",
    "# songs_df[\"release_date\"] = pd.to_datetime(songs_df[\"release_date\"], format=\"mixed\").astype(int)/ 10**9\n",
    "# songs_df[\"release_date\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZlaliWxLALuJ"
   },
   "source": [
    "Load the V, A, D dimension values from the original MuSe dataset and add them to the rest of the data.\n",
    "^ Join V, A, D columns by key columns title and author."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "eSAE8pJSALuK"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "orig_dataset = pd.read_csv(\"datasets/muse_v3.csv\")\n",
    "orig_dataset.columns\n",
    "orig_dataset.set_index(\"track\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "9jlVYFr-JHwl"
   },
   "outputs": [],
   "source": [
    "VAL_COLS = [\"valence_tags\",\"arousal_tags\",\"dominance_tags\"]\n",
    "songs_df = songs_df.join(orig_dataset[VAL_COLS], how=\"inner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "caik4_-rALuL"
   },
   "source": [
    "Model will take data as (`X_train`,`y_train`)\n",
    "- `X_train` is a 2D NumPy array of shape `n_samples` x `n_features`, i.e. one song per row, one metadata feature per column\n",
    "- `y_train` is just convert the \"mood\" column into a 1D NumPy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iHXhqrfrALuL",
    "outputId": "bef1e385-37ef-4a3b-b2c3-f94babf482b7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77934.5"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How much should we take for training, testing?\n",
    "songs_df.index.size\n",
    "\n",
    "0.7 * songs_df.index.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "dgq7cI7qALuN"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "DROP_COLS = VAL_COLS+[\"artist\"]\n",
    "# use a constant random state for reproducibility\n",
    "# X = songs_df.drop(columns=DROP_COLS)\n",
    "# y = songs_df[VAL_COLS]\n",
    "X_train, X_test, y_train, y_test = train_test_split(songs_df.drop(columns=DROP_COLS), songs_df[VAL_COLS],\n",
    "                                                    test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up Weights & Biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m API key must be 40 characters long, yours was 13\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: C:\\Users\\17788\\.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mOdYtnvzALuN"
   },
   "source": [
    "## Multi-Layer Perceptron\n",
    "[PyTorch tutorial](https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html)\n",
    "\n",
    "[Building a Regression Model in PyTorch](https://machinelearningmastery.com/building-a-regression-model-in-pytorch/)\n",
    "\n",
    "[ChatGPT PyTorch Regression Model](https://chat.openai.com/share/8e1237ca-a45f-4abc-8740-25ca00d72bbf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.0932310599637163\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "mlp = MLPRegressor(solver='lbfgs', hidden_layer_sizes=())\n",
    "\n",
    "# terrible score lol\n",
    "mlp_regression = mlp.fit(X_train, y_train)\n",
    "print(mlp_regression.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   key  loudness    tempo  duration_ms  time_signature\n",
      "track                                                                 \n",
      "Beast                2    -3.669  139.984       240987               4\n",
      "II                   8    -9.682  140.337       714347               4\n",
      "Breathe              1   -28.443   84.554       138000               4\n",
      "sigur ros 8          4    -8.847  156.475       705093               4\n",
      "Amazing Grace        2   -16.918   79.362       471067               3\n",
      "...                ...       ...      ...          ...             ...\n",
      "San Bernardino       5   -10.845  155.817       199053               4\n",
      "Ysbeidiau Heulog     4    -5.743  140.020       170533               4\n",
      "Visions              9    -8.927  128.013       366400               4\n",
      "A Arte do Insulto    0    -3.357  178.374       110987               4\n",
      "Chemical Love        9   -14.020   71.276       228027               4\n",
      "\n",
      "[89068 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               key  loudness    tempo  duration_ms  \\\n",
      "track                                                                \n",
      "I Will                           0    -7.378  100.325       260000   \n",
      "Breathe                          2    -5.496  108.066       333533   \n",
      "Angel's Redemption               2   -20.916   96.784       148820   \n",
      "Butterflies                      4    -6.137  141.970       219053   \n",
      "Intro                           11    -6.918   78.570        89307   \n",
      "...                            ...       ...      ...          ...   \n",
      "Prologue                         9   -17.987   74.221       154413   \n",
      "Rollercoaster                    7    -4.817  136.726       226253   \n",
      "Shadows                         11    -7.468   89.895       248640   \n",
      "The Woodlands National Anthem    0   -10.826  125.156       239307   \n",
      "War Dance                        0   -12.565  172.393       237093   \n",
      "\n",
      "                               time_signature  \n",
      "track                                          \n",
      "I Will                                      5  \n",
      "Breathe                                     4  \n",
      "Angel's Redemption                          4  \n",
      "Butterflies                                 4  \n",
      "Intro                                       4  \n",
      "...                                       ...  \n",
      "Prologue                                    3  \n",
      "Rollercoaster                               4  \n",
      "Shadows                                     4  \n",
      "The Woodlands National Anthem               4  \n",
      "War Dance                                   4  \n",
      "\n",
      "[22267 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        valence_tags  arousal_tags  \\\n",
      "track                                                                \n",
      "Elijah                                      6.825000      5.105000   \n",
      "My Saddest Day                              4.024000      4.010000   \n",
      "Jehovah's Witness                           3.745000      5.370000   \n",
      "Spooky                                      4.400000      6.000000   \n",
      "Let's Do Everything for the First Time      7.805000      5.440000   \n",
      "...                                              ...           ...   \n",
      "Anthem                                      4.873378      3.793108   \n",
      "Fragile                                     5.326341      3.302073   \n",
      "Remember (Christmas)                        6.680000      4.370000   \n",
      "Jerusalem                                   6.260000      4.390000   \n",
      "Es-So                                       6.430000      4.350000   \n",
      "\n",
      "                                        dominance_tags  \n",
      "track                                                   \n",
      "Elijah                                        6.135000  \n",
      "My Saddest Day                                4.358000  \n",
      "Jehovah's Witness                             4.525000  \n",
      "Spooky                                        4.480000  \n",
      "Let's Do Everything for the First Time        7.012500  \n",
      "...                                                ...  \n",
      "Anthem                                        5.285676  \n",
      "Fragile                                       5.235610  \n",
      "Remember (Christmas)                          5.050000  \n",
      "Jerusalem                                     4.885000  \n",
      "Es-So                                         5.820000  \n",
      "\n",
      "[22267 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 valence_tags  arousal_tags  dominance_tags\n",
      "track                                                      \n",
      "Knockin' On Joe      3.470000      3.673333        3.166667\n",
      "Rain                 3.950000      5.570000        4.480000\n",
      "Twelve               3.150000      3.320000        3.150000\n",
      "This Side Of Me      6.760000      3.943333        6.326667\n",
      "Love Paradox         4.000000      5.700000        5.700000\n",
      "...                       ...           ...             ...\n",
      "Run                  6.035000      4.680000        5.915000\n",
      "Home                 6.935000      2.670000        6.100000\n",
      "Peter Street         8.210000      6.500000        7.210000\n",
      "Northern Lights      2.053333      3.913333        3.660000\n",
      "On the Run           5.406667      4.277778        4.994444\n",
      "\n",
      "[89068 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_test: (22267, 5)\n",
      "Shape of y_test: (22267, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of X_test:\", X_test.shape)\n",
    "print(\"Shape of y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# credit: https://stackoverflow.com/questions/71198218/the-simple-mlp-nn-for-regression-in-pytorch-very-slow-learning-rev2\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, output_size, dropout_p=0.5):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size1)\n",
    "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.fc3 = nn.Linear(hidden_size2, output_size)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "# convert dataframe to PyTorch Tensor\n",
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32).to(device)\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32).to(device)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).to(device)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).to(device)\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size, shuffle=False, pin_memory=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_size = X_train.shape[1]\n",
    "# hidden_size1 = 6\n",
    "# hidden_size2 = 4\n",
    "# output_size = y_train.shape[1]  # Assuming y_train has multiple output columns\n",
    "# model = NeuralNetwork(input_size, hidden_size1, hidden_size2, output_size).to(device)\n",
    "\n",
    "hyperparams = dict(\n",
    "    input_size=X_train.shape[1],\n",
    "    hidden_size1=5,\n",
    "    hidden_size2=3,\n",
    "    output_size=y_train.shape[1],\n",
    "    dropout_p=0.5,\n",
    "    lr=0.001,\n",
    "    epochs=20,\n",
    "    device=device.type\n",
    ")\n",
    "model = NeuralNetwork(hyperparams[\"input_size\"], hyperparams[\"hidden_size1\"], hyperparams[\"hidden_size2\"], hyperparams[\"output_size\"], hyperparams[\"dropout_p\"]).to(device)\n",
    "\n",
    "sweep_config = {\n",
    "    \"name\": \"MLP Sweep\",\n",
    "    \"method\": \"grid\",\n",
    "    \"metric\": {\"goal\": \"minimize\", \"name\": \"test loss\"},\n",
    "    \"parameters\": {\n",
    "        \"hidden_size1\": {\"values\": list(range(3,9))},\n",
    "        \"hidden_size2\": {\"values\": list(range(3,9))},\n",
    "        \"epochs\": {\"values\": [5, 10, 15]},\n",
    "        \"dropout_p\": {\"values\": [0.3, 0.5, 0.7]},\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mapplesdaddy\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\17788\\OneDrive - Simon Fraser University (1sfu)\\Desktop\\School\\CMPT353\\Project\\CMPT353Project\\wandb\\run-20240404_162852-fj0n1z3b</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/applesdaddy/Music%20Mood%20Prediction/runs/fj0n1z3b' target=\"_blank\">MLP Regressor</a></strong> to <a href='https://wandb.ai/applesdaddy/Music%20Mood%20Prediction' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/applesdaddy/Music%20Mood%20Prediction' target=\"_blank\">https://wandb.ai/applesdaddy/Music%20Mood%20Prediction</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/applesdaddy/Music%20Mood%20Prediction/runs/fj0n1z3b' target=\"_blank\">https://wandb.ai/applesdaddy/Music%20Mood%20Prediction/runs/fj0n1z3b</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.init(project=\"Music Mood Prediction\", name=\"MLP Regressor\", config=hyperparams)\n",
    "config = wandb.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss() \n",
    "optimizer = optim.Adam(model.parameters(), lr=config[\"lr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (1864209426.py, line 13)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[25], line 13\u001b[1;36m\u001b[0m\n\u001b[1;33m    running_loss = 0.0\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train the model\n",
    "def train():\n",
    "    wandb.watch(model, criterion, log=\"all\", log_freq=10)\n",
    "\n",
    "    num_epochs = hyperparams[\"epochs\"]\n",
    "    avg_loss = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        avg_loss += train_epoch()\n",
    "    avg_loss /= num_epochs\n",
    "        \n",
    "def train_epoch(train_loader, model, optimizer):\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "    for inputs, targets in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    wandb.log({\"train loss\": epoch_loss}, step=epoch)\n",
    "    print(f'epoch {epoch+1} of {num_epochs}: loss = {epoch_loss:.4f}')\n",
    "\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: [ 7.00000e+00 -1.15520e+01  1.44172e+02  3.17107e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 1.10000e+01 -1.15760e+01  1.14327e+02  2.45493e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 0.00000e+00 -1.47170e+01  1.02407e+02  1.95467e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 4.00000e+00 -8.60600e+00  1.47477e+02  3.05120e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 5.00000e+00 -1.33090e+01  1.14013e+02  2.74147e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 9.00000e+00 -1.59620e+01  7.68100e+01  2.11513e+05  3.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 5.00000e+00 -6.34300e+00  1.55955e+02  3.49333e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 6.00000e+00 -1.18920e+01  1.28645e+02  2.72053e+05  5.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 1.10000e+01 -4.18600e+00  1.23146e+02  1.95467e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 0.00000e+00 -1.30390e+01  1.40998e+02  2.69360e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 5.00000e+00 -6.49800e+00  9.50680e+01  2.68827e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 5.00000e+00 -7.51300e+00  1.86731e+02  3.39080e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 9.0000e+00 -7.0110e+00  1.3411e+02  3.5564e+05  4.0000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 1.10000e+01 -5.88400e+00  1.56096e+02  2.62667e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 4.00000e+00 -8.31300e+00  1.11895e+02  2.71427e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 6.00000e+00 -1.41830e+01  1.01007e+02  4.73467e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 6.00000e+00 -7.91800e+00  1.59959e+02  1.99488e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 0.00000e+00 -8.77100e+00  1.76544e+02  2.26067e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 5.00000e+00 -1.31110e+01  1.27343e+02  1.25867e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 9.0000e+00 -9.5740e+00  7.5969e+01  3.4600e+05  4.0000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 2.0000e+00 -1.7676e+01  5.9121e+01  3.9520e+04  3.0000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 2.00000e+00 -1.20190e+01  1.09012e+02  1.54173e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 7.00000e+00 -1.57930e+01  1.55837e+02  2.43227e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 1.00000e+01 -1.36610e+01  1.25811e+02  1.46147e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 8.00000e+00 -8.02800e+00  1.40099e+02  2.32973e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 1.10000e+01 -3.99200e+00  1.20203e+02  2.45440e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 7.0000e+00 -1.7292e+01  9.4475e+01  9.9960e+04  4.0000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 0.00000e+00 -6.89000e+00  1.20032e+02  2.83213e+05  3.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 1.00000e+00 -6.63100e+00  1.06887e+02  2.09440e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 4.00000e+00 -3.03100e+00  1.21980e+02  1.99093e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 7.00000e+00 -7.57600e+00  8.99080e+01  2.36333e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 1.00000e+00 -7.28700e+00  1.76129e+02  3.08253e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 4.00000e+00 -3.81900e+00  9.59990e+01  2.27347e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 5.00000e+00 -2.05550e+01  1.15163e+02  1.56933e+05  3.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 7.00000e+00 -6.90500e+00  1.24966e+02  6.09133e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 1.00000e+00 -1.17730e+01  1.00137e+02  1.71000e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 4.0000e+00 -1.2342e+01  1.6484e+02  6.5600e+04  4.0000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 2.00000e+00 -1.05410e+01  1.19989e+02  9.39730e+04  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 5.00000e+00 -1.52260e+01  1.17256e+02  2.79719e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 4.00000e+00 -1.70780e+01  1.05462e+02  2.64347e+05  5.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 1.10000e+01 -5.65700e+00  1.53208e+02  2.34973e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 7.00000e+00 -7.24000e+00  1.21738e+02  3.14600e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 1.00000e+01 -9.52100e+00  6.10410e+01  2.84693e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 4.00000e+00 -7.46300e+00  1.13971e+02  2.34827e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 8.00000e+00 -7.41600e+00  1.17878e+02  2.69468e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 0.00000e+00 -7.25000e+00  1.45007e+02  1.96852e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 1.00000e+00 -2.16680e+01  7.66980e+01  2.84032e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 9.00000e+00 -6.24000e+00  1.33988e+02  1.84067e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 1.10000e+01 -1.04870e+01  9.00200e+01  2.29267e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 4.00000e+00 -1.24970e+01  1.34999e+02  3.81347e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 8.00000e+00 -2.18460e+01  1.22747e+02  2.67600e+05  5.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 1.10000e+01 -5.06400e+00  1.75890e+02  1.51107e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 1.00000e+00 -4.27200e+00  1.22008e+02  1.69027e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 1.10000e+01 -1.15590e+01  1.39562e+02  3.85920e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 8.00000e+00 -1.45630e+01  1.28947e+02  3.32733e+05  3.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 6.00000e+00 -3.32200e+00  1.30009e+02  3.76040e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 8.00000e+00 -9.72500e+00  1.17074e+02  2.93653e+05  3.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 4.00000e+00 -1.02240e+01  1.15165e+02  2.62520e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 9.00000e+00 -1.45130e+01  7.90920e+01  1.17173e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 6.00000e+00 -1.18660e+01  1.14032e+02  2.02093e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 5.00000e+00 -1.02830e+01  1.39154e+02  2.62787e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 3.00000e+00 -5.54300e+00  1.02963e+02  2.09333e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 7.00000e+00 -4.92900e+00  1.35092e+02  2.20853e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 1.10000e+01 -5.16700e+00  1.41517e+02  2.79800e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 4.00000e+00 -4.95500e+00  1.63423e+02  2.19920e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 0.0000e+00 -4.1360e+00  8.9980e+01  2.3548e+05  4.0000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 9.00000e+00 -1.34530e+01  1.16508e+02  4.56047e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 7.00000e+00 -9.54500e+00  1.37883e+02  2.40533e+05  3.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 9.00000e+00 -1.65830e+01  1.76046e+02  9.77100e+04  5.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 7.00000e+00 -5.65000e+00  1.22024e+02  2.25813e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 8.00000e+00 -2.66750e+01  1.43714e+02  1.18293e+05  1.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 2.00000e+00 -7.60100e+00  1.07889e+02  2.73933e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 7.00000e+00 -4.24800e+00  1.20017e+02  2.03560e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 2.00000e+00 -6.44200e+00  1.45000e+02  4.89931e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 1.10000e+01 -3.08100e+00  1.31211e+02  2.67360e+05  3.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 8.00000e+00 -1.07600e+01  1.23597e+02  1.97280e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 6.00000e+00 -9.12200e+00  1.13915e+02  4.31467e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 1.00000e+01 -7.17900e+00  1.03564e+02  2.85373e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 4.0000e+00 -1.1051e+01  9.8014e+01  2.9432e+05  4.0000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 9.00000e+00 -1.07030e+01  2.15967e+02  4.19373e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 9.00000e+00 -7.89000e+00  1.34332e+02  3.59240e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 8.00000e+00 -7.09700e+00  1.24999e+02  1.78027e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 6.00000e+00 -1.04200e+01  1.37389e+02  3.14773e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 0.00000e+00 -1.14440e+01  1.20176e+02  3.67240e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 9.00000e+00 -8.80100e+00  1.37720e+02  3.23573e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 5.00000e+00 -1.05540e+01  1.35372e+02  4.50947e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 9.00000e+00 -5.72800e+00  1.38017e+02  1.88493e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 1.00000e+00 -6.73500e+00  8.36830e+01  2.41027e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 7.0000e+00 -8.1300e+00  8.2735e+01  3.1232e+05  3.0000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 2.00000e+00 -1.37870e+01  1.25985e+02  3.32213e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 7.00000e+00 -1.00460e+01  1.43825e+02  3.96960e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 6.00000e+00 -8.88100e+00  1.29771e+02  2.58573e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 6.00000e+00 -6.16800e+00  1.12785e+02  3.75307e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 1.00000e+00 -3.97100e+00  1.39932e+02  2.28240e+05  3.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 3.00000e+00 -7.36000e+00  1.76637e+02  2.70307e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 9.00000e+00 -1.38020e+01  1.06203e+02  2.72960e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 8.00000e+00 -8.56800e+00  1.15994e+02  1.67333e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 1.00000e+01 -9.74400e+00  1.34754e+02  2.75440e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 4.00000e+00 -2.16000e+00  1.80336e+02  3.00427e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 2.00000e+00 -3.85200e+00  1.20072e+02  3.61867e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 0.00000e+00 -5.59000e-01  8.24540e+01  2.47273e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 1.00000e+00 -5.63700e+00  1.77779e+02  1.45427e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 9.00000e+00 -1.21080e+01  1.02992e+02  4.45180e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 7.00000e+00 -1.81400e+00  1.00073e+02  2.59587e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 5.0000e+00 -3.0360e+01  6.9290e+01  1.0492e+05  3.0000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 7.00000e+00 -1.36140e+01  1.18169e+02  1.44373e+05  3.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 9.00000e+00 -8.05900e+00  1.24043e+02  3.01773e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 1.00000e+01 -5.92400e+00  9.55190e+01  2.32347e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 1.10000e+01 -4.44400e+00  1.02008e+02  2.56013e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 0.00000e+00 -6.64600e+00  1.91299e+02  2.00760e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 0.00000e+00 -1.03570e+01  1.68964e+02  2.32760e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 5.00000e+00 -4.56700e+00  9.89440e+01  2.30888e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 4.00000e+00 -9.96000e+00  7.28190e+01  2.28147e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 1.1000e+01 -1.0857e+01  1.0881e+02  2.6816e+05  4.0000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 1.00000e+01 -2.49160e+01  1.63019e+02  2.24373e+05  1.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 2.00000e+00 -2.31730e+01  8.66460e+01  3.22667e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 1.00000e+01 -2.21750e+01  7.56370e+01  2.45507e+05  3.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 4.00000e+00 -3.09700e+00  1.06337e+02  1.99453e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 7.0000e+00 -7.4050e+00  9.1951e+01  2.6898e+05  4.0000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 9.0000e+00 -6.9700e+00  7.9978e+01  2.3744e+05  4.0000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 9.00000e+00 -6.05500e+00  1.03011e+02  1.47280e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 7.00000e+00 -4.32100e+00  1.80169e+02  2.57707e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 8.00000e+00 -4.48000e+00  1.40599e+02  1.21720e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 2.00000e+00 -1.87030e+01  8.55380e+01  3.30933e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 5.0000e+00 -1.0219e+01  8.1157e+01  4.8850e+05  5.0000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 8.00000e+00 -8.77600e+00  9.79610e+01  4.05583e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 1.10000e+01 -1.21430e+01  1.20476e+02  1.97493e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 1.00000e+00 -1.38540e+01  1.24059e+02  3.25107e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 1.00000e+00 -1.04820e+01  1.37025e+02  4.54792e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 0.00000e+00 -8.21300e+00  1.43066e+02  2.55853e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 0.00000e+00 -9.64100e+00  1.39988e+02  5.73453e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 2.00000e+00 -6.57100e+00  1.00002e+02  2.30320e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 1.00000e+00 -9.91800e+00  1.26738e+02  7.31867e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 9.00000e+00 -4.56400e+00  1.36010e+02  2.17059e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 4.00000e+00 -1.82380e+01  7.89900e+01  1.59933e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 9.00000e+00 -2.42980e+01  1.19865e+02  9.47610e+04  1.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 0.00000e+00 -2.55000e+00  1.50061e+02  2.18760e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 4.00000e+00 -4.85100e+00  8.97540e+01  2.42453e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 1.00000e+00 -9.91700e+00  1.03560e+02  2.49933e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 1.00000e+01 -7.90100e+00  1.25008e+02  2.43360e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 1.00000e+01 -4.75200e+00  1.01678e+02  2.02589e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 6.00000e+00 -7.86400e+00  8.85990e+01  2.46627e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 1.10000e+01 -8.66200e+00  1.24893e+02  2.00040e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 7.00000e+00 -1.15270e+01  1.18391e+02  2.37067e+05  3.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 4.0000e+00 -1.3549e+01  7.6062e+01  5.3436e+05  4.0000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 8.00000e+00 -3.82200e+00  1.05088e+02  2.88227e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 5.00000e+00 -1.43830e+01  1.21449e+02  2.52293e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 2.00000e+00 -5.01300e+00  1.57012e+02  2.72213e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 9.00000e+00 -8.96200e+00  1.41927e+02  3.66987e+05  3.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 7.00000e+00 -1.47290e+01  1.25064e+02  2.23267e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 7.00000e+00 -4.50100e+00  1.68831e+02  2.38293e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 7.00000e+00 -5.46500e+00  1.57281e+02  2.27093e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 2.00000e+00 -1.09160e+01  1.57321e+02  2.58387e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 5.00000e+00 -8.64800e+00  1.31109e+02  2.42853e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 6.00000e+00 -1.01800e+01  7.66000e+01  3.37173e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 4.00000e+00 -1.15270e+01  1.99824e+02  2.65800e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 3.00000e+00 -1.28520e+01  1.09599e+02  2.30307e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 3.0000e+00 -1.0131e+01  1.6018e+02  2.4948e+05  4.0000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 0.00000e+00 -6.03900e+00  9.80040e+01  2.53813e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 9.00000e+00 -1.26140e+01  1.41405e+02  1.81067e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 5.0000e+00 -1.0818e+01  7.9977e+01  3.8612e+05  4.0000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 1.00000e+00 -5.28300e+00  1.18859e+02  2.36467e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 2.00000e+00 -5.63400e+00  1.41899e+02  3.29720e+05  3.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 3.00000e+00 -9.49200e+00  1.38145e+02  3.19747e+05  3.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 2.00000e+00 -1.15100e+01  7.38720e+01  1.98453e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 0.00000e+00 -1.23140e+01  9.93790e+01  2.61507e+05  3.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 9.0000e+00 -3.6270e+00  8.1840e+01  1.7056e+05  4.0000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 4.00000e+00 -1.42090e+01  9.90050e+01  1.55181e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 3.00000e+00 -1.62250e+01  1.34766e+02  1.76267e+05  3.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 1.00000e+01 -1.24650e+01  6.24000e+01  3.21333e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 0.00000e+00 -5.50000e+00  1.26986e+02  2.31307e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 9.00000e+00 -1.18550e+01  8.24260e+01  2.47693e+05  3.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 9.00000e+00 -8.52500e+00  1.21261e+02  2.37133e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 0.00000e+00 -3.75600e+00  1.46967e+02  1.93829e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 1.00000e+00 -4.69400e+00  8.70480e+01  3.42912e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 1.00000e+01 -4.95600e+00  1.44223e+02  1.45080e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 1.1000e+01 -1.0249e+01  9.0172e+01  2.3908e+05  4.0000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 2.00000e+00 -4.95700e+00  1.67612e+02  2.59316e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 1.00000e+00 -5.38600e+00  1.27983e+02  2.59987e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 0.00000e+00 -2.05800e+01  8.65100e+01  1.72224e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 7.0000e+00 -7.3620e+00  1.1067e+02  2.0284e+05  4.0000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 0.00000e+00 -1.69650e+01  8.71770e+01  2.03787e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 1.00000e+00 -8.71500e+00  1.68144e+02  2.93040e+05  3.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 7.00000e+00 -1.39970e+01  1.23482e+02  2.49067e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 1.00000e+00 -7.18300e+00  8.71010e+01  2.02547e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 2.00000e+00 -1.91990e+01  1.32976e+02  2.01467e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 2.00000e+00 -2.65650e+01  1.19972e+02  4.12400e+04  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 2.00000e+00 -1.59390e+01  2.03406e+02  1.63480e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 1.10000e+01 -9.92900e+00  9.65480e+01  2.38533e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 9.00000e+00 -9.41800e+00  1.77464e+02  3.31800e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 0.00000e+00 -1.33310e+01  1.04843e+02  4.54680e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 1.00000e+00 -1.13910e+01  1.14289e+02  2.96000e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 7.0000e+00 -8.1330e+00  7.8870e+01  1.9196e+05  4.0000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 1.10000e+01 -5.57400e+00  1.28376e+02  1.61947e+05  5.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 5.00000e+00 -4.86500e+00  1.15978e+02  2.14713e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 5.00000e+00 -4.08800e+00  1.42146e+02  2.31707e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 9.00000e+00 -1.11850e+01  1.27413e+02  2.58203e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 0.00000e+00 -9.47100e+00  1.85064e+02  2.53973e+05  3.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 2.00000e+00 -3.31240e+01  8.04400e+01  1.36147e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 1.00000e+01 -2.46320e+01  8.12300e+01  2.13068e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 5.00000e+00 -4.99700e+00  1.03992e+02  2.86427e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 2.00000e+00 -3.76500e+00  1.40296e+02  2.44107e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 3.00000e+00 -7.39300e+00  1.10738e+02  2.44773e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 2.00000e+00 -6.07400e+00  1.12061e+02  2.92160e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 6.00000e+00 -6.84400e+00  1.05008e+02  3.22760e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 0.00000e+00 -1.19690e+01  1.00673e+02  3.69707e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 6.00000e+00 -3.71600e+00  1.69937e+02  2.46453e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 7.00000e+00 -5.30700e+00  9.25900e+01  2.43024e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 2.00000e+00 -1.03780e+01  1.18505e+02  1.20613e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 9.00000e+00 -7.14900e+00  8.85360e+01  1.96441e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 4.00000e+00 -4.18100e+00  8.29210e+01  2.23747e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 4.00000e+00 -5.68700e+00  1.60088e+02  2.20200e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 4.00000e+00 -1.12040e+01  1.14325e+02  2.44173e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 1.10000e+01 -1.81880e+01  1.00489e+02  3.13667e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 0.00000e+00 -7.68300e+00  1.20067e+02  3.09720e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 7.00000e+00 -4.83200e+00  1.32462e+02  1.66293e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 7.0000e+00 -1.3083e+01  9.6483e+01  2.3116e+05  4.0000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 0.00000e+00 -1.02610e+01  1.15071e+02  1.78947e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 9.00000e+00 -8.11600e+00  1.48137e+02  1.49800e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 7.00000e+00 -7.32500e+00  1.79484e+02  2.27227e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 9.00000e+00 -1.10860e+01  8.40230e+01  2.37293e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 4.00000e+00 -1.09190e+01  1.13931e+02  2.79067e+05  3.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 0.00000e+00 -1.34000e+00  1.10116e+02  1.63257e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 4.00000e+00 -8.25100e+00  1.65714e+02  3.32467e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 7.00000e+00 -3.28100e+00  8.40160e+01  2.51507e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 2.00000e+00 -1.25910e+01  7.61770e+01  1.88867e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 7.00000e+00 -7.63500e+00  9.49860e+01  2.04707e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 0.00000e+00 -5.63900e+00  1.16994e+02  2.15267e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 8.00000e+00 -2.13980e+01  1.39696e+02  1.97069e+05  3.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 7.0000e+00 -1.0339e+01  9.3988e+01  8.6126e+04  4.0000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 5.00000e+00 -9.45500e+00  1.70229e+02  2.46733e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 7.0000e+00 -1.1282e+01  9.2331e+01  4.6840e+05  4.0000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 8.00000e+00 -1.85350e+01  1.12265e+02  5.43904e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 3.00000e+00 -8.29300e+00  8.64560e+01  2.65453e+05  5.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 1.10000e+01 -8.22800e+00  1.43099e+02  2.82133e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 2.00000e+00 -9.29000e+00  1.04896e+02  5.72133e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 6.00000e+00 -7.64700e+00  1.21983e+02  3.51667e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 2.00000e+00 -2.77940e+01  6.97540e+01  2.08027e+05  3.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 0.00000e+00 -5.48500e+00  1.69083e+02  2.30707e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 2.00000e+00 -6.24400e+00  1.24660e+02  2.23173e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 0.0000e+00 -1.5167e+01  9.4251e+01  1.3716e+05  4.0000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 1.00000e+00 -7.72100e+00  1.01960e+02  1.76947e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 8.00000e+00 -6.39900e+00  1.15011e+02  2.17813e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 1.000000e+00 -1.775700e+01  1.161970e+02  1.453467e+06  3.000000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 1.00000e+01 -8.87900e+00  1.77923e+02  4.46427e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 0.00000e+00 -2.11480e+01  1.10422e+02  3.81400e+04  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 7.0000e+00 -1.5024e+01  8.3617e+01  5.3324e+05  3.0000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 1.00000e+01 -1.63550e+01  1.70667e+02  1.40283e+05  5.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 9.00000e+00 -6.76600e+00  1.24491e+02  2.99040e+05  3.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 5.00000e+00 -5.86800e+00  1.47056e+02  2.32247e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 2.0000e+00 -2.9810e+00  1.2295e+02  2.5136e+05  3.0000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 8.00000e+00 -1.45720e+01  1.78731e+02  1.36800e+05  3.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 1.00000e+01 -1.10060e+01  6.65520e+01  3.45667e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 0.00000e+00 -8.54800e+00  1.40026e+02  2.51436e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 1.10000e+01 -1.03400e+01  1.15010e+02  2.48827e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 4.00000e+00 -1.38880e+01  9.84240e+01  2.78973e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 7.00000e+00 -2.07550e+01  1.36938e+02  1.74172e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 9.00000e+00 -3.63500e+00  1.48346e+02  2.01200e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 7.00000e+00 -1.65230e+01  1.24461e+02  2.71800e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 5.00000e+00 -3.14000e+00  1.15191e+02  1.64280e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 7.00000e+00 -6.31200e+00  7.49320e+01  2.19467e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 4.00000e+00 -1.03290e+01  7.41930e+01  1.46427e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 9.00000e+00 -5.57800e+00  1.14036e+02  3.32080e+05  1.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 6.00000e+00 -9.50200e+00  9.00300e+01  2.60267e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 3.00000e+00 -1.06480e+01  1.59926e+02  1.87267e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 1.00000e+00 -7.54400e+00  1.01692e+02  1.85640e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 5.00000e+00 -1.18350e+01  1.06159e+02  3.05613e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 0.00000e+00 -7.08000e+00  1.85183e+02  2.41467e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 4.00000e+00 -4.31000e+00  7.49840e+01  1.42973e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 4.00000e+00 -8.57500e+00  1.22438e+02  2.39280e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 4.00000e+00 -1.21360e+01  1.25106e+02  3.59853e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 5.00000e+00 -1.16480e+01  9.70240e+01  2.72213e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 4.00000e+00 -1.10910e+01  1.32141e+02  3.33107e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 9.00000e+00 -8.16200e+00  1.03020e+02  3.00707e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 1.00000e+01 -6.17600e+00  9.14600e+01  2.32533e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 4.00000e+00 -6.58100e+00  1.45031e+02  2.36867e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 4.00000e+00 -6.42100e+00  1.32991e+02  1.95920e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 5.00000e+00 -2.81400e+00  1.41961e+02  2.35907e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 2.00000e+00 -2.29400e+01  6.76450e+01  7.72067e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 1.00000e+00 -1.01650e+01  1.15944e+02  2.65067e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 0.00000e+00 -1.74040e+01  8.99440e+01  5.16787e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 7.00000e+00 -1.02980e+01  1.17994e+02  2.68387e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 2.00000e+00 -7.15700e+00  1.15929e+02  2.80987e+05  5.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 4.0000e+00 -1.2505e+01  1.0935e+02  2.7460e+05  4.0000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 9.00000e+00 -6.41700e+00  8.48060e+01  1.97973e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 5.0000e+00 -5.7710e+00  1.1605e+02  1.6716e+05  4.0000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 1.00000e+01 -6.21100e+00  1.00509e+02  3.40400e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 6.0000e+00 -1.0786e+01  9.7995e+01  3.0232e+05  4.0000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 6.0000e+00 -3.9040e+00  9.4979e+01  2.1968e+05  4.0000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 4.0000e+00 -8.4200e+00  1.8091e+02  3.0020e+05  4.0000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 0.00000e+00 -1.95650e+01  9.42080e+01  3.02213e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 1.10000e+01 -5.19700e+00  9.80090e+01  2.03613e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 9.00000e+00 -1.24240e+01  8.94550e+01  2.46507e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 8.0000e+00 -9.0920e+00  9.2915e+01  2.7628e+05  4.0000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 0.00000e+00 -4.40000e+00  1.65915e+02  2.40227e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 9.00000e+00 -5.83000e+00  1.22897e+02  1.84667e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 9.00000e+00 -8.19500e+00  1.58323e+02  3.41123e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 4.00000e+00 -5.84300e+00  1.45927e+02  2.56426e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 7.00000e+00 -1.05790e+01  1.19988e+02  2.99534e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 8.00000e+00 -8.18900e+00  1.23014e+02  2.24147e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 0.00000e+00 -5.99200e+00  1.41726e+02  3.01320e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 2.00000e+00 -6.86800e+00  1.58724e+02  2.01200e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 1.00000e+00 -1.09810e+01  1.29981e+02  3.87141e+05  3.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 6.00000e+00 -8.21400e+00  1.30022e+02  2.69560e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 7.00000e+00 -5.64500e+00  1.01569e+02  1.93813e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 4.00000e+00 -1.12570e+01  9.41080e+01  2.08467e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 0.00000e+00 -1.77510e+01  1.37254e+02  2.38160e+05  3.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 5.00000e+00 -8.79400e+00  1.09697e+02  4.19467e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 2.00000e+00 -7.70500e+00  1.29233e+02  1.32333e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 7.0000e+00 -1.3360e+01  1.0816e+02  2.2420e+05  4.0000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 1.00000e+00 -9.70400e+00  1.44899e+02  8.01680e+05  3.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 2.00000e+00 -9.14700e+00  1.40120e+02  3.77147e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 9.00000e+00 -2.18100e+01  1.35158e+02  1.28667e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 9.00000e+00 -1.47370e+01  1.14607e+02  2.95837e+05  3.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 3.0000e+00 -1.6564e+01  7.2194e+01  2.1676e+05  3.0000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 5.00000e+00 -1.34460e+01  1.58237e+02  2.29133e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 1.00000e+01 -5.27900e+00  1.54292e+02  2.23867e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 0.00000e+00 -1.04310e+01  7.25990e+01  3.09822e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 1.10000e+01 -6.74400e+00  1.10014e+02  2.34040e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 7.0000e+00 -7.4230e+00  1.6668e+02  2.7152e+05  4.0000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 4.00000e+00 -6.53500e+00  1.17036e+02  2.40234e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 9.00000e+00 -9.44900e+00  1.29387e+02  1.70247e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 2.00000e+00 -4.07800e+00  1.62000e+02  2.70547e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 1.00000e+01 -4.30700e+00  1.39872e+02  2.11387e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 1.00000e+00 -1.99290e+01  1.26023e+02  6.20027e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 1.1000e+01 -1.0304e+01  9.2012e+01  2.0116e+05  4.0000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 2.00000e+00 -3.20140e+01  1.46233e+02  1.98000e+05  3.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 1.00000e+00 -1.49910e+01  7.89160e+01  2.63941e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 3.00000e+00 -1.22880e+01  1.53515e+02  1.34908e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 1.10000e+01 -7.76500e+00  1.27498e+02  2.03282e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 8.00000e+00 -9.16800e+00  1.21489e+02  3.03467e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 5.00000e+00 -1.47130e+01  1.20017e+02  1.46627e+05  3.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 6.00000e+00 -1.01480e+01  6.26960e+01  1.41693e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 2.00000e+00 -7.33400e+00  1.47996e+02  2.92813e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 9.00000e+00 -1.46540e+01  1.26106e+02  3.21280e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 9.00000e+00 -3.95600e+00  7.92390e+01  2.19413e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 7.00000e+00 -7.64900e+00  1.20019e+02  2.50800e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 9.00000e+00 -8.71700e+00  1.74686e+02  1.66107e+05  3.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 7.00000e+00 -1.07820e+01  1.87807e+02  2.72907e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 7.00000e+00 -6.17600e+00  1.14208e+02  3.14293e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 1.10000e+01 -7.08300e+00  1.11705e+02  3.86533e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 7.00000e+00 -1.19390e+01  1.10059e+02  1.48667e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 5.00000e+00 -7.19600e+00  1.05111e+02  3.03093e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 7.00000e+00 -5.08900e+00  1.32513e+02  2.51240e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 1.00000e+01 -7.98700e+00  1.20019e+02  1.56947e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 8.0000e+00 -2.6340e+00  8.3566e+01  2.6020e+05  4.0000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 8.0000e+00 -1.1212e+01  7.9800e+01  2.5692e+05  4.0000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "input: [ 5.00000e+00 -7.60100e+00  1.04989e+02  3.17960e+05  4.00000e+00]\n",
      "output: [5.4975758 4.2417927 5.2519846]\n",
      "test loss: 1.7080\n"
     ]
    }
   ],
   "source": [
    "def test(test_loader: torch.utils.data.DataLoader, model: torch.nn.Module, criterion: torch.nn.Module,\n",
    "         log_table: wandb.Table):\n",
    "    \"\"\"record test examples and predictions in W&B table\"\"\"\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    test_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader:\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            test_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            # Display and log some test examples <- input and output\n",
    "            print(f'input: {inputs[0].cpu().numpy()}')\n",
    "            print(f'output: {outputs[0].cpu().numpy()}')\n",
    "            log_table.add_data(\n",
    "\n",
    "            )\n",
    "\n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        wandb.log({\"test loss\": test_loss})\n",
    "        print(f'test loss: {test_loss:.4f}')\n",
    "\n",
    "test_table = wandb.Table(columns=[\n",
    "    \"song name\",\n",
    "    \"artist\",\n",
    "    \"tempo\",\n",
    "    \"key signature\",\n",
    "    \"loudness\",\n",
    "    \"time signature\",\n",
    "    \"duration (ms)\",\n",
    "    \"predicted valence\",\n",
    "    \"predicted arousal\",\n",
    "    \"predicted dominance\"\n",
    "])\n",
    "test(test_loader, model, criterion, test_table)\n",
    "wandb.log({\"test examples\": test_table})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sweep_id = wandb.sweep(sweep_config, project=\"Music Mood Prediction\")\n",
    "# wandb.agent(sweep_id, function=pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a146f366f62b46cca1a065abfcd4f5fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.004 MB of 0.083 MB uploaded\\r'), FloatProgress(value=0.05314559823308141, max=1.â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test loss</td><td>â–</td></tr><tr><td>train loss</td><td>â–ˆâ–â–â–â–â–â–â–â–â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test loss</td><td>1.70797</td></tr><tr><td>train loss</td><td>1.69165</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">MLP Regressor</strong> at: <a href='https://wandb.ai/t0m_x/Music%20Mood%20Prediction/runs/uqq9ebm7/workspace' target=\"_blank\">https://wandb.ai/t0m_x/Music%20Mood%20Prediction/runs/uqq9ebm7/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240402_182153-uqq9ebm7/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FWg9vkc-L-wN"
   },
   "source": [
    "## Histogram-Based Gradient Boosted Tree\n",
    "- [scikit-learn tutorial](https://scikit-learn.org/stable/modules/ensemble.html#histogram-based-gradient-boosting)\n",
    "- [regressor API reference](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.HistGradientBoostingRegressor.html#sklearn.ensemble.HistGradientBoostingRegressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:om9zgq1y) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4789946900847178abfe5960109d72a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.004 MB of 0.004 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Histogram-based Gradient Boosting Regressor</strong> at: <a href='https://wandb.ai/applesdaddy/Music%20Mood%20Prediction/runs/om9zgq1y' target=\"_blank\">https://wandb.ai/applesdaddy/Music%20Mood%20Prediction/runs/om9zgq1y</a><br/> View project at: <a href='https://wandb.ai/applesdaddy/Music%20Mood%20Prediction' target=\"_blank\">https://wandb.ai/applesdaddy/Music%20Mood%20Prediction</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240404_165816-om9zgq1y\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:om9zgq1y). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9edb70552d264911a38167cc4595b2ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011111111111111112, max=1.0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\17788\\OneDrive - Simon Fraser University (1sfu)\\Desktop\\School\\CMPT353\\Project\\CMPT353Project\\wandb\\run-20240404_165824-3jvsu9j3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/applesdaddy/Music%20Mood%20Prediction/runs/3jvsu9j3' target=\"_blank\">Histogram-based Gradient Boosting Regressor</a></strong> to <a href='https://wandb.ai/applesdaddy/Music%20Mood%20Prediction' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/applesdaddy/Music%20Mood%20Prediction' target=\"_blank\">https://wandb.ai/applesdaddy/Music%20Mood%20Prediction</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/applesdaddy/Music%20Mood%20Prediction/runs/3jvsu9j3' target=\"_blank\">https://wandb.ai/applesdaddy/Music%20Mood%20Prediction/runs/3jvsu9j3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/applesdaddy/Music%20Mood%20Prediction/runs/3jvsu9j3?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x29d0dc1cc90>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(\n",
    "    project=\"Music Mood Prediction\",\n",
    "    name=\"Histogram-based Gradient Boosting Regressor\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "hgbt = MultiOutputRegressor(HistGradientBoostingRegressor(random_state=0))\n",
    "regression = hgbt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 8\u001b[0m\n\u001b[0;32m      2\u001b[0m wandb\u001b[38;5;241m.\u001b[39mlog({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCoefficient of Correlation (R^2)\u001b[39m\u001b[38;5;124m\"\u001b[39m: r2})\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# The outliers chart only supports univariate (i.e. 1D output) regression\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# wandb.sklearn.plot_regressor(regression,\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m#                             X_train, X_test,\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m#                             y_train, y_test,\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m#                             model_name=\"hist_gradient_boosting_regressor\")\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[43mwandb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msklearn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot_learning_curve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mregression\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m wandb\u001b[38;5;241m.\u001b[39msklearn\u001b[38;5;241m.\u001b[39mplot_summary_metrics(regression, X_train, y_train, X_test, y_test)\n",
      "File \u001b[1;32mc:\\Users\\17788\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wandb\\sklearn\\plot\\shared.py:86\u001b[0m, in \u001b[0;36mlearning_curve\u001b[1;34m(model, X, y, cv, shuffle, random_state, train_sizes, n_jobs, scoring)\u001b[0m\n\u001b[0;32m     83\u001b[0m     train_sizes \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m1.0\u001b[39m, \u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m     84\u001b[0m y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(y)\n\u001b[1;32m---> 86\u001b[0m learning_curve_chart \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearning_curve\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     87\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_sizes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\n\u001b[0;32m     88\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     90\u001b[0m wandb\u001b[38;5;241m.\u001b[39mlog({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlearning_curve\u001b[39m\u001b[38;5;124m\"\u001b[39m: learning_curve_chart})\n",
      "File \u001b[1;32mc:\\Users\\17788\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wandb\\sklearn\\calculate\\learning_curve.py:29\u001b[0m, in \u001b[0;36mlearning_curve\u001b[1;34m(model, X, y, cv, shuffle, random_state, train_sizes, n_jobs, scoring)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearning_curve\u001b[39m(\n\u001b[0;32m     14\u001b[0m     model,\n\u001b[0;32m     15\u001b[0m     X,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     22\u001b[0m     scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     23\u001b[0m ):\n\u001b[0;32m     24\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Train model on datasets of varying size and generates plot of score vs size.\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \n\u001b[0;32m     26\u001b[0m \u001b[38;5;124;03m    Called by plot_learning_curve to visualize learning curve. Please use the function\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;124;03m    plot_learning_curve() if you wish to visualize your learning curves.\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m     train_sizes, train_scores, test_scores \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_selection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearning_curve\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscoring\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m     train_scores_mean \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(train_scores, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     41\u001b[0m     test_scores_mean \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(test_scores, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\17788\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:214\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    210\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    211\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    212\u001b[0m         )\n\u001b[0;32m    213\u001b[0m     ):\n\u001b[1;32m--> 214\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    224\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\17788\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:1683\u001b[0m, in \u001b[0;36mlearning_curve\u001b[1;34m(estimator, X, y, groups, train_sizes, cv, scoring, exploit_incremental_learning, n_jobs, pre_dispatch, verbose, shuffle, random_state, error_score, return_times, fit_params)\u001b[0m\n\u001b[0;32m   1680\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m n_train_samples \u001b[38;5;129;01min\u001b[39;00m train_sizes_abs:\n\u001b[0;32m   1681\u001b[0m         train_test_proportions\u001b[38;5;241m.\u001b[39mappend((train[:n_train_samples], test))\n\u001b[1;32m-> 1683\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1684\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1685\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1686\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1687\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1688\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1689\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1690\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1691\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1692\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1693\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1694\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1695\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1696\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_times\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1697\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1698\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_test_proportions\u001b[49m\n\u001b[0;32m   1699\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1700\u001b[0m results \u001b[38;5;241m=\u001b[39m _aggregate_score_dicts(results)\n\u001b[0;32m   1701\u001b[0m train_scores \u001b[38;5;241m=\u001b[39m results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, n_unique_ticks)\u001b[38;5;241m.\u001b[39mT\n",
      "File \u001b[1;32mc:\\Users\\17788\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\17788\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[0;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Users\\17788\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Users\\17788\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\17788\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:754\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    752\u001b[0m     score_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time \u001b[38;5;241m-\u001b[39m fit_time\n\u001b[0;32m    753\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m return_train_score:\n\u001b[1;32m--> 754\u001b[0m         train_scores \u001b[38;5;241m=\u001b[39m \u001b[43m_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    756\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    757\u001b[0m     total_time \u001b[38;5;241m=\u001b[39m score_time \u001b[38;5;241m+\u001b[39m fit_time\n",
      "File \u001b[1;32mc:\\Users\\17788\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:810\u001b[0m, in \u001b[0;36m_score\u001b[1;34m(estimator, X_test, y_test, scorer, error_score)\u001b[0m\n\u001b[0;32m    808\u001b[0m         scores \u001b[38;5;241m=\u001b[39m scorer(estimator, X_test)\n\u001b[0;32m    809\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 810\u001b[0m         scores \u001b[38;5;241m=\u001b[39m \u001b[43mscorer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    811\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    812\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(scorer, _MultimetricScorer):\n\u001b[0;32m    813\u001b[0m         \u001b[38;5;66;03m# If `_MultimetricScorer` raises exception, the `error_score`\u001b[39;00m\n\u001b[0;32m    814\u001b[0m         \u001b[38;5;66;03m# parameter is equal to \"raise\".\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\17788\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py:527\u001b[0m, in \u001b[0;36m_PassthroughScorer.__call__\u001b[1;34m(self, estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m    525\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    526\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Method that wraps estimator.score\"\"\"\u001b[39;00m\n\u001b[1;32m--> 527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\17788\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:760\u001b[0m, in \u001b[0;36mRegressorMixin.score\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    718\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return the coefficient of determination of the prediction.\u001b[39;00m\n\u001b[0;32m    719\u001b[0m \n\u001b[0;32m    720\u001b[0m \u001b[38;5;124;03mThe coefficient of determination :math:`R^2` is defined as\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;124;03m:class:`~sklearn.multioutput.MultiOutputRegressor`).\u001b[39;00m\n\u001b[0;32m    756\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    758\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m r2_score\n\u001b[1;32m--> 760\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    761\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m r2_score(y, y_pred, sample_weight\u001b[38;5;241m=\u001b[39msample_weight)\n",
      "File \u001b[1;32mc:\\Users\\17788\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\multioutput.py:305\u001b[0m, in \u001b[0;36m_MultiOutputEstimator.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    303\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe base estimator should implement a predict method\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 305\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    306\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimators_\u001b[49m\n\u001b[0;32m    307\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39masarray(y)\u001b[38;5;241m.\u001b[39mT\n",
      "File \u001b[1;32mc:\\Users\\17788\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\17788\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[0;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Users\\17788\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Users\\17788\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\17788\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_hist_gradient_boosting\\gradient_boosting.py:1510\u001b[0m, in \u001b[0;36mHistGradientBoostingRegressor.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1507\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m   1508\u001b[0m \u001b[38;5;66;03m# Return inverse link of raw predictions after converting\u001b[39;00m\n\u001b[0;32m   1509\u001b[0m \u001b[38;5;66;03m# shape (n_samples, 1) to (n_samples,)\u001b[39;00m\n\u001b[1;32m-> 1510\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loss\u001b[38;5;241m.\u001b[39mlink\u001b[38;5;241m.\u001b[39minverse(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raw_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mravel())\n",
      "File \u001b[1;32mc:\\Users\\17788\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_hist_gradient_boosting\\gradient_boosting.py:1052\u001b[0m, in \u001b[0;36mBaseHistGradientBoosting._raw_predict\u001b[1;34m(self, X, n_threads)\u001b[0m\n\u001b[0;32m   1048\u001b[0m \u001b[38;5;66;03m# We intentionally decouple the number of threads used at prediction\u001b[39;00m\n\u001b[0;32m   1049\u001b[0m \u001b[38;5;66;03m# time from the number of threads used at fit time because the model\u001b[39;00m\n\u001b[0;32m   1050\u001b[0m \u001b[38;5;66;03m# can be deployed on a different machine for prediction purposes.\u001b[39;00m\n\u001b[0;32m   1051\u001b[0m n_threads \u001b[38;5;241m=\u001b[39m _openmp_effective_n_threads(n_threads)\n\u001b[1;32m-> 1052\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_iterations\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1053\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predictors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraw_predictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_binned\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_threads\u001b[49m\n\u001b[0;32m   1054\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1055\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m raw_predictions\n",
      "File \u001b[1;32mc:\\Users\\17788\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_hist_gradient_boosting\\gradient_boosting.py:1080\u001b[0m, in \u001b[0;36mBaseHistGradientBoosting._predict_iterations\u001b[1;34m(self, X, predictors, raw_predictions, is_binned, n_threads)\u001b[0m\n\u001b[0;32m   1073\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1074\u001b[0m     predict \u001b[38;5;241m=\u001b[39m partial(\n\u001b[0;32m   1075\u001b[0m         predictor\u001b[38;5;241m.\u001b[39mpredict,\n\u001b[0;32m   1076\u001b[0m         known_cat_bitsets\u001b[38;5;241m=\u001b[39mknown_cat_bitsets,\n\u001b[0;32m   1077\u001b[0m         f_idx_map\u001b[38;5;241m=\u001b[39mf_idx_map,\n\u001b[0;32m   1078\u001b[0m         n_threads\u001b[38;5;241m=\u001b[39mn_threads,\n\u001b[0;32m   1079\u001b[0m     )\n\u001b[1;32m-> 1080\u001b[0m raw_predictions[:, k] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\17788\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_hist_gradient_boosting\\predictor.py:71\u001b[0m, in \u001b[0;36mTreePredictor.predict\u001b[1;34m(self, X, known_cat_bitsets, f_idx_map, n_threads)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Predict raw values for non-binned data.\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \n\u001b[0;32m     50\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;124;03m    The raw predicted values.\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     70\u001b[0m out \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], dtype\u001b[38;5;241m=\u001b[39mY_DTYPE)\n\u001b[1;32m---> 71\u001b[0m \u001b[43m_predict_from_raw_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_left_cat_bitsets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     75\u001b[0m \u001b[43m    \u001b[49m\u001b[43mknown_cat_bitsets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf_idx_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     78\u001b[0m \u001b[43m    \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     79\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "r2 = regression.score(X_test, y_test)\n",
    "wandb.log({\"Coefficient of Correlation (R^2)\": r2})\n",
    "# The outliers chart only supports univariate (i.e. 1D output) regression\n",
    "# wandb.sklearn.plot_regressor(regression,\n",
    "#                             X_train, X_test,\n",
    "#                             y_train, y_test,\n",
    "#                             model_name=\"hist_gradient_boosting_regressor\")\n",
    "wandb.sklearn.plot_learning_curve(regression, X_train, y_train)\n",
    "wandb.sklearn.plot_summary_metrics(regression, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, GridSearchCV, KFold\n",
    "\n",
    "param_grid = {\n",
    "    \"learning_rate\": [0.1, 0.01, 0.001],\n",
    "    \"n_estimators\": [100, 200, 300],\n",
    "    \"max_depth\": [3, 5, 7],\n",
    "    \"min_samples_split\": [20, 35, 50],\n",
    "    \"min_samples_leaf\": list(range(1,6))\n",
    "}\n",
    "\n",
    "cv_fold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "grid_search = GridSearchCV(hgbt, param_grid, cv=cv_fold, n_jobs=-1, scoring=\"neg_mean_squared_error\")\n",
    "param_search_results = grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_model = param_search_results.best_estimator_\n",
    "best_params = param_search_results.best_params_\n",
    "wandb.log({\"Coefficient of Correlation (R^2)\": best_model.score(X_test, y_test)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.sklearn.plot_learning_curve(best_model, X_train, y_train)\n",
    "wandb.sklearn.plot_summary_metrics(best_model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GLaM-AJCALuO",
    "outputId": "64c608d5-3a6d-43f2-8e1e-7760b65b7a82"
   },
   "outputs": [],
   "source": [
    "regression.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x2rHNCIzALuO"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
